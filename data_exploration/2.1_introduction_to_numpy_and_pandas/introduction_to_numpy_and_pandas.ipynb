{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2.1: Introduction to NumPy & pandas\n",
    "\n",
    "[**Lecture slides**](https://docs.google.com/presentation/d/1R9mpEMQpoIyZGTTlKhTg_5jb9-mMDA1zDXtOK_75yYQ/edit?usp=sharing)\n",
    "\n",
    "\n",
    "This lecture, we are getting to know the two python libraries at the heart of data analysis: [NumPy](https://numpy.org/) and [pandas](https://pandas.pydata.org/).\n",
    "\n",
    "**Learning goals:**\n",
    "- Explain the difference between NumPy ndarrays, pandas Series, and pandas DataFrames\n",
    "- Construct ndarrays, Series, and DataFrames\n",
    "- Carry out basic operations on a ndarrays, Series, and DataFrames\n",
    "- Show the need for efficient maths & data librairies\n",
    "\n",
    "---\n",
    "\n",
    "## 1. NumPy\n",
    "\n",
    "üí™ Before we start playing with numpy, we have to install the package to have access to the library. I have added `numpy` and `pandas` to the `Pipfile` in the root directory of this repository. To install them in your virtual environment, please close this jupyter server, go to the root directory of the repo, and run the following:\n",
    "\n",
    "    pipenv install\n",
    "    \n",
    "`pipenv` should read the updated `Pipfile` and take care of the installation for you. Once it's done, we can re-open the jupyter server and have access to NumPy üòé.\n",
    "\n",
    "‚ÑπÔ∏è When importing NumPy, the convention is to use the name `np`. You don't technically have to follow this convention, but please do, as it will make your code more readable and shareable. \n",
    "\n",
    "üí™ Appreciate running your first numpy import... this will be the first of many! üéä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Array creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the world of NumPy, the main class is the `ndarray`. According to the [documentation](https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html):\n",
    "> An ndarray is a multidimensional container of items of the same type and size\n",
    "\n",
    "In other words, they are efficient data structures for vectors and matrices, like these ones:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "a = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "4\n",
    "\\end{bmatrix}\n",
    "; \\,\n",
    "B = \n",
    "\\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "Vectors, like $a$ above, can be created by passing a python list as argument to `np.array()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks a lot like a regular list... üßê Fear not, arrays can also be _multi-dimentional_ üëª. Matrices like $B$ can be created by passing one python list per row to `np.array()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy is _intended_ for maths. It's in the name! So it comes with a lots of neat inbuilt constructor methods for `ndarray`. Here's some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üí™ Now your turn, can you use `.linspace()` to return a 1D array of 8 equally spaced numbers between -3 & 10? Pro-tip: always check the documentation if this is your first time using a method. You can do that with the `?` prefix in this notebook, or by looking for it online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß† What's the main difference between `.arange()` and `.linspace()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most convenient things about NumPy is that it's very integrated with python. It overloads a lot of operators. For example, accessing a number in an `ndarray` is exactly like selecting an element in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 1, 2, 3, 5, 8, 13])\n",
    "a[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [list slicing notation](https://stackoverflow.com/questions/509211/understanding-slice-notation) works as well üî™:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat! This makes working with `ndarray` very \"natural\". In fact, sometimes it's easy to forget if you are dealing with an `ndarray` or a simple list, so try to keep track of your data types. You can always check them using the [`type()`](https://www.geeksforgeeks.org/python-type-function/) built-in function.\n",
    "\n",
    "NumPy also overloads arithmetic operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have noticed, piecewise operations are the default with python arithmetic operators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß† Can you guess what the `@` operator does with `ndarray`? Check your answer by looking up the official documentation (or searching online)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 NumPy Data Types\n",
    "\n",
    "\n",
    "NumPy tries to make the _api_ very integrated with native python, but we know that in the backend... it runs C code! So it's not super clear what classes are running under the hood. Let's investigate what data types are used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3])\n",
    "type(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already know, NumPy arrays are not python lists... but what's inside the `ndarray`? We fed a list of `int`s in the constructor in the cell just above, so maybe the `ndarray` holds `int`s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(arr[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üôÄ Wait a minute, that's not an `int`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.random.random(10)[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's not a normal `float`! NumPy uses its own [data types](https://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html) so it can be lightning fast ‚ö°Ô∏è. These are called `dtypes`. In fact, there are many more `dtypes` than there are primitive data types in python! Here's a complete [list](https://numpy.org/devdocs/user/basics.types.html). No need to learn them all, NumPy will take care of the casting for you most of the time. But it's good to be aware that they exist should you be debugging your code, or worried about performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 NumPy Performance\n",
    "\n",
    "Let's see if NumPy is really as fast as it claims!\n",
    "\n",
    "First, let's make a 1D `ndarray` with of length 10000. We'll fill it with random numbers $\\in [0,1]$.\n",
    "\n",
    "‚ÑπÔ∏è It's a good idea to explicitly set the seeds where you can, as it keeps results reproducible. A data scientist's nightmare would be to achieve a new state of the art result and be unable to repeat it afterwards! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "arr = np.random.random(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's use NumPy's `.tolist()` method to convert the array to a native python list. This will also cast the elements from `np.float64` to python `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = arr.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the two contain the same data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The array is of size: {len(arr)}')\n",
    "print(f'The list is of size: {len(lst)}')\n",
    "\n",
    "print('The first three elements of the array are:')\n",
    "print(arr[:3])\n",
    "print('The first three elements of the list are:')\n",
    "print(lst[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's imagine we want to filter elements that are smaller than a threshold. We can make one function for our NumPy `arr`, and one for our python `lst`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_list(lst, threshold):\n",
    "    new_lst = []\n",
    "    for e in lst:\n",
    "        if e > threshold:\n",
    "            new_lst.append(e)\n",
    "    return new_lst\n",
    "\n",
    "def filter_array(arr, threshold):\n",
    "    return arr[arr > threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the notation for the array filter is more terse? This uses a _boolean mask_. They are very useful and we'll cover them in more detail next lecture.\n",
    "\n",
    "üí™ Can you write another function called `filter_list_comprehension` where you use list comprehensions instead of a for loop to filter the values of `lst`? It should fit in one line! Add your code to the cell below. The unit test should not fail when the cell is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_list_comprehension(lst, threshold):\n",
    "    # INSERT YOUR CODE HERE\n",
    "\n",
    "def test_filter_list_comprehension():\n",
    "    assert len(filter_list_comprehension(lst, 0.5)) == 4936\n",
    "    print('Success! üéâ')\n",
    "\n",
    "test_filter_list_comprehension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehensions are terse, fast, and awesome. You should use them when you can, but be aware that sticking complex chains of operations in one line can also quickly become illegible!\n",
    "\n",
    "Now let's use the `timeit` [magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html) to time the execution of our functions. `timeit` will run the expressions in loops to measure the average running time, so this may take a few seconds. We'll use an arbitrary threshold value of 0.7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit filter_list(lst, 0.7)\n",
    "%timeit filter_list_comprehension(lst, 0.7)\n",
    "%timeit filter_array(arr, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's fast! üèé The list comprehension is faster than the for loop, but numpy is almost ten times as fast!\n",
    "\n",
    "Gaining $300\\,\\mu s$ might not sound like like much, but remember this is a test with (only) 10000 values. When we'll deal with multi-dimensional arrays of millions of values, this speed up can make a huge difference!  \n",
    "\n",
    "üß† What's the difference between `timeit` and `time`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pandas\n",
    "\n",
    "‚ÑπÔ∏è The convention is to use the name `pd` when importing pandas. Just like `np` & NumPy, you don't technically have to follow this convention, but please always do!\n",
    " \n",
    "üí™ This will also be your first time of many to import pandas! üéä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main classes in the world of pandas. The first one is the `Series`. According to the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html):\n",
    "> A Series is a one-dimensional ndarray with axis labels.\n",
    "\n",
    "Notice how pandas leverage NumPy `ndarray`s as data structures. Also observe that a `Series` object wraps the array with \"axis labels\", also called an _index_. But before we dig into indices, let's see how `Series` are created. Just like the 1D `ndarray`, a Series constructor can take a python list as argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output statement details the NumPy `dtype` used in the inner `ndarray` of the Series. \n",
    "\n",
    "Overloading of list slicing syntax and arithmetic operators is also similar to NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[2::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s + s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so far, a Series looks and acts pretty much the same as a 1D `ndarray`. One exception is the \"axis labels\" we can see on the left hand side of the output statement: `0 1 2 3`.\n",
    "\n",
    "These form the [`index`]() of the Series. `ndarray`s also have an index, since we can access them with the `arr[i]` syntax, but in pandas Series, the index is _explicit_. This means that we can select it and manipulate it as a first class object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index[2:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexes don't have to be incremental integers. For example, let's sort a Series and see what happens to it.\n",
    "\n",
    "üí™ Sort the rows of the following series by _value_. No need to write a function here, just modify `s` so that the unit test passes. Pro-tip: look up the [official documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, 2, 4, 0])\n",
    "print(f'This is the original series:\\n{s}')\n",
    "# INSERT CODE HERE\n",
    "print(f'This is the sorted series:\\n{s}')\n",
    "\n",
    "def test_sorted(s):\n",
    "    assert s.is_monotonic_increasing\n",
    "    print('Success! üéâ')\n",
    "        \n",
    "test_sorted(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the indices \"stuck\" with their value in the sorted series, and are now disordered? We can also use other data types as index labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This series has a string index:\\n')\n",
    "s = pd.Series({'seven': 7, 'ate':8, 'nine':9})\n",
    "print(s)\n",
    "print('\\nThis series has a date index:\\n')\n",
    "s = pd.Series(data=np.linspace(666, 1337, 3), index=pd.date_range('20121221', periods=3))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series are cool, but `ndarray`s could be _multi-dimensional_ and we learned that was useful in machine learning. This leads us to the second main class of pandas: the `DataFrame`.\n",
    "\n",
    "### 2.2 DataFrame\n",
    "\n",
    "According to the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):\n",
    "> A DataFrame is a two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
    "\n",
    "The important term here is _tabular_. `DataFrame`s are the excel sheets of python! In other words, a `DataFrame` is a 2D indexed array.  This includes an inner 2D `ndarray`, the same row index as the `Series` class, as well as a list of column names. In fact, each column in a DataFrame is just a named `Series`.\n",
    "\n",
    "Just like 2D `ndarray`s, we can create `DataFrame`s with one list per row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the index `0 1` on the LHS, and the column names `0 1 2 3` on top of the data array. Since columns are first class citizens in pandas (just like indices), we can manipulate and modify them directly! These default column names are bit a boring. Let's change them to something else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['üëå', 'üëΩ', 'ayy', 'lmao']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like `ndarray`s and `Series`, `DataFrames` are closely integrated with python and overload common operators. They are also element wise by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df + df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df * df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've only dealt with toy data this notebook, here's a little teaser of what one can do in a few lines of python with the pandas library. üòè Let's create some fake financial data by adding a noise term to two lines. We then load this in a date-indexed `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "data = {}\n",
    "data['stonks'] = np.linspace(99, 101, 100) + np.random.random(100)\n",
    "data['not stonks'] = np.linspace(101, 99, 100) + np.random.random(100)\n",
    "stacks = pd.DataFrame(data=data, index=pd.date_range('20191223', periods=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 100 rows of our `DataFrame` might be a bit too much to fit on our screen, but sometimes it's still helpful to keep an eye on the data. We can use `.head()`, which only returns the first 5 rows of our `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas integrates [matplotlib](https://matplotlib.org/) in their api, so it's _super_ easy to plot `DataFrame` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization is an entire field of data science, and we'll go over it in more detail during another lecture. But remember that the `DataFrame.plot` api is handy when exploring data. üë®‚Äçüé®\n",
    "\n",
    "üß†üß† Can you explain how the lines defining `data['stonks']` and `data['not stonks']` translate to these plotted lines? Pro-tip: When dealing `ndarray`s, it helps to keep track of the dimension of your objects between operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary\n",
    "\n",
    "Today, we have learned about **NumPy** and **pandas**, and how they are key tools for manipulating data in python. We understood that the **`ndarray`** is an efficient data structure for **matrices**, that the **`Series`** adds an **index** to these arrays, and that the **`DataFrame`** extends them in 2D to represent **tabular** data. We have learned how to **construct** and do **basic operations** with these three objects, by looking up **official documentation**. We've also measured their **performance** compared to python data structures. We even got a little taster of what financial analysis can look like with pandas. üí∏\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Resources\n",
    "\n",
    "## Core Resources\n",
    "\n",
    "- [**Slides**](https://docs.google.com/presentation/d/1R9mpEMQpoIyZGTTlKhTg_5jb9-mMDA1zDXtOK_75yYQ/edit?usp=sharing)\n",
    "- [ndarray official documentation](https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html)\n",
    "- [ndarray creation documentation](https://docs.scipy.org/doc/numpy/user/quickstart.html#array-creation)\n",
    "- [Python Data Science handbook on numpy](https://jakevdp.github.io/PythonDataScienceHandbook/02.00-introduction-to-numpy.html)\n",
    "- [Series official documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)\n",
    "- [DataFrame official documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n",
    "- [Pandas getting started documentation](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html)\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [List slicing explained](https://stackoverflow.com/questions/509211/understanding-slice-notation)  \n",
    "Stackoverflow post succinctly explaining the python list slicing notation\n",
    "- [Learn NumPy in 5 minutes](https://youtu.be/xECXZ3tyONo)  \n",
    "Terse video summary of basic numpy operations\n",
    "- [3 numPy image transformations on baby yoda](https://towardsdatascience.com/3-numpy-image-transformations-on-baby-yoda-c27c1409b411)  \n",
    "Short blog post with examples of ndarray manipulation\n",
    "- [The ultimate begginer's guide to NumPy](https://towardsdatascience.com/the-ultimate-beginners-guide-to-numpy-f5a2f99aef54)  \n",
    "- [Numpy example list](http://scipy.github.io/old-wiki/pages/Numpy_Example_List)  \n",
    "Examples of all numpy methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
